# ğŸ§  JumpNet
## ğŸ§  JumpNet Dataset Builder â€“ Behavior Cloning Data Pipeline

This repository provides a complete **data preparation pipeline** for training a machine learning model to play a jump-based game (e.g., *Geometry Dash*) using **behavior cloning**.

> ğŸ“Œ Before a model can learn to play, it must first **observe** â€” thatâ€™s why a clean, high-quality dataset is essential.

---

## ğŸ“¸ What This Pipeline Does

This pipeline converts raw gameplay and keylogging recordings into a structured `.npz` file containing labeled training data:

Each data entry contains:

* âœ… RGB image of the screen
* âœ… Label (1 = jump, 0 = no jump)
* âœ… Keypress vector (multi-hot)
* âœ… Hold duration of key
* âœ… Phase ("press")
* âœ… Frame index for video sync

---

## ğŸ”— Prerequisites â€“ Start With Data Collection

This pipeline **assumes** you have already recorded raw data using our separate modular tool:

### ğŸ›  Modular Data Recorder Tool (REQUIRED):

* âœ… Snipping region selector
* âœ… Key logger
* âœ… Real-time frame synchronizer

> ğŸ“… Use this tool **first** to generate your raw `.npz` files:

* ğŸ”— Dev.to Part 1: [Modular Snip Recorder](https://dev.to/ertugrulmutlu/modular-snip-recorder-a-data-collection-tool-for-behavior-cloning-12-5di8)
* ğŸ”— Dev.to Part 2: [Advanced Dataset Viewer](https://dev.to/ertugrulmutlu/modular-snip-recorder-a-data-collection-tool-for-behavior-cloning-22-1lgl)
* ğŸ”— GitHub: [Data Scrap Tool + Viewer](https://github.com/Ertugrulmutlu/-Data-Scrap-Tool-Advanced-Dataset-Viewer)

---

## ğŸ§± Pipeline Structure

This repo includes several modular scripts to process and structure your data:

| Step | File                        | Purpose                                          |
| ---- | --------------------------- | ------------------------------------------------ |
| 1ï¸âƒ£  | `Data_preproccer.py`        | Extract clean `press-release` jump pairs         |
| 2ï¸âƒ£  | `Data_merge.py`             | Merge multiple `.npz` files                      |
| 3ï¸âƒ£  | `Data_argumentation.py`     | Augment positive samples with noise, flip, shift |
| 4ï¸âƒ£  | `Data_Negativ_scrapping.py` | Extract "non-jump" frames from raw video         |
| 5ï¸âƒ£  | `Data_reducier.py`          | Downsample negatives for class balance           |
| 6ï¸âƒ£  | `Data_merge_final.py`       | Merge final positive + negative dataset          |
| âœ…    | `deneme.py`                 | Preview final dataset entries                    |

---

## ğŸ“¦ Example Output

A few entries from the final dataset look like this:

```
ğŸ“ Entry #1
  image.shape     : (227, 227, 3)
  label           : 1.0
  keys_raw        : [1.]
  hold_duration   : [0.294]
  phase           : press
  frame_index     : 7720
```

---

## ğŸ§° Installation

**Install required packages:**

```bash
pip install -r Data_Process_requirements.txt
```

---

## â–¶ï¸ How to Run the Pipeline

After running each `.py` script, you can optionally inspect the output `.npz` file using the **Modular Viewer Tool** from Part 2:

> ğŸ” This allows you to visually verify the result after each stage of the pipeline and detect any anomalies or malformed data early on.

**Step-by-step example (manual):**

```bash
# Step 1: Extract positive pressâ€“release pairs
python Data_preproccer.py
# âœ… Then use the Viewer tool to inspect the generated pressâ€“release dataset
python Data_preproccer.py

# Step 2: Merge multiple .npz files
python Data_merge.py
# âœ… Inspect the merged file using the Viewer
python Data_merge.py

# Step 3: Augment positive samples
python Data_argumentation.py
# âœ… Open the augmented output in the Viewer to confirm transformations
python Data_argumentation.py

# Step 4: Extract negative samples from video
python Data_Negativ_scrapping.py
# âœ… Check extracted negative samples visually with the Viewer
python Data_Negativ_scrapping.py

# Step 5: Reduce excessive negative frames
python Data_reducier.py
# âœ… View the reduced dataset for balance verification
python Data_reducier.py

# Step 6: Merge final dataset
python Data_merge_final.py
# âœ… Final sanity check using the Viewer before training
python Data_merge_final.py

# Optional: Visualize sample entries
python deneme.py
```

---

## ğŸ§  Data Structure Explained

Each dataset entry is a tuple with the following structure:

```python
(
  image,          # np.ndarray â€“ RGB frame of size (227, 227, 3)
  label,          # float â€“ 1.0 for jump, 0.0 for no jump
  keys_raw,       # list/array â€“ multi-hot key state (e.g., [1.] if 'w' pressed)
  hold_duration,  # list/array â€“ key hold duration in seconds (e.g., [0.294])
  phase,          # str â€“ phase of the action (usually "press")
  frame_index     # int â€“ frame index used for video synchronization
)
```

This structure ensures that the model can learn *when* and *how long* to jump, based on visual input and frame timing.

---

## ğŸ”— Blog Reference

This project is part of a multi-stage blog series:

* ğŸ§¹ Part 1: [Modular Snip Recorder â€“ Data Collection](https://dev.to/ertugrulmutlu/modular-snip-recorder-a-data-collection-tool-for-behavior-cloning-12-5di8)
* ğŸ§¹ Part 2: [Advanced Viewer & Inspector](https://dev.to/ertugrulmutlu/modular-snip-recorder-a-data-collection-tool-for-behavior-cloning-22-1lgl)
* ğŸš€ Part 3: *(this repo)* JumpNet Dataset Builder â€“ From Video to Labeled Data
* ğŸ•’ Part 4: *Coming soon â€“ Model Training & Evaluation*

---

## ğŸ§‘â€ğŸ’» Troubleshooting

### âŒ `ValueError: object too deep for desired array`

* This error typically occurs when saving complex objects without using `dtype=object`.
* âœ… Fix: Ensure arrays are saved as `np.array(data, dtype=object)`.

### âŒ `KeyError: 'data'`

* This means the `.npz` file is missing a required `data` key.
* âœ… Fix: Check the generation step and confirm that `'data'` is part of the saved file.

### âŒ `cv2.error` in `Data_Negativ_scrapping.py`

* Likely due to an invalid or missing video file.
* âœ… Fix: Confirm that `cv2.VideoCapture(video_path).isOpened()` returns `True`.

### âŒ Model overfits quickly due to lack of shuffling

* âœ… Fix: Always apply `np.random.shuffle(all_data)` in `Data_merge_final.py` before saving.

---
